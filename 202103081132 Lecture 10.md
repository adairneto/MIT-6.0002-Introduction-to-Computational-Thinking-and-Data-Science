# Lecture 10: Understanding Experimental Data 2

Tags: #algorithms #python #modeling #simulation #datascience #rsquared

## Introduction

Which model to use? Well, why do we use a model in the first place?

A good model explain the phenomenon and allows us to make predictions.

How mystery data was generated:

```python
def genNoisyParabolicData(a, b, c, xVals, fName):
    yVals = []
    for x in xVals:
        theoreticalVal = a*x**2 + b*x + c
        yVals.append(theoreticalVal\
        + random.gauss(0, 35))
    f = open(fName,'w')
    f.write('x        y\n')
    for i in range(len(yVals)):
        f.write(str(yVals[i]) + ' ' + str(xVals[i]) + '\n')
    f.close()
    
#parameters for generating data
xVals = range(-10, 11, 1)
a, b, c = 3.0, 0.0, 0.0
degrees = (2, 4, 8, 16)

#generate data
random.seed(0)
genNoisyParabolicData(a, b, c, xVals,
                      'Dataset 1.txt')
genNoisyParabolicData(a, b, c, xVals,
                      'Dataset 2.txt')

xVals1, yVals1 = getData('Dataset 1.txt')
models1 = genFits(xVals1, yVals1, degrees)
testFits(models1, degrees, xVals1, yVals1,
        'DataSet 1.txt')

pylab.figure()
xVals2, yVals2 = getData('Dataset 2.txt')
models2 = genFits(xVals2, yVals2, degrees)
testFits(models2, degrees, xVals2, yVals2,
        'DataSet 2.txt')
```

Why is a 16 degree a better fit if the data came from a polynomial of order 2?

How well do we fill the model to the training data?

## Cross-Validation

Generate models using one dataset, and then test them on another dataset.

```python
pylab.figure()
testFits(models1, degrees, xVals2, yVals2,
        'DataSet 2/Model 1')
pylab.figure()
testFits(models2, degrees, xVals1, yVals1,
        'DataSet 1/Model 2')
```

On the example case, the degree 16 model 1 (trained on dataset 1) won't perform optimally on the dataset 2.

Constant problem in Statistics: *overfitting*. Too many free variables.

If we only fit the model to the training data, and look how well it does, we can get to a far too complex model. 

**Train on one dataset and test on another.**

## Fitting a Quadratic to a Perfect Line

```python
xVals = (0,1,2,3)
yVals = xVals
pylab.plot(xVals, yVals, label = 'Actual values')
a,b,c = pylab.polyfit(xVals, yVals, 2)
print('a =', round(a, 4), 'b =', round(b, 4),
      'c =', round(c, 4))
estYVals = pylab.polyval((a,b,c), xVals)
pylab.plot(xVals, estYVals, 'r--', label = 'Predictive values')
print('R-squared = ', rSquared(yVals, estYVals))
pylab.legend(loc = 'best')
```

Gives $a=0=c$.

Adding a perfect point in a line doesn't affect, a small measurement gives a very close to 1 R-squared.

With them both, R-squared goes to 0.70 and the predicted line doesn't fit.

What if we fitted a line? It would do a very good job, R-squared very close to 1.

Overly-complex model works poorly on data not included in the training set.

## Returning to the Spring Problem

A quadratic model fits better. But Hooke's law says it's linear.

The model works until reach elastic limit of spring.

Fit different models to different segments of data.

How to do **cross validation** here?

If the data is small:

- Leave the first one out
- Build model
- Test it with the left element
- Repet until Len(dataset)
- Average test results

If the data is big:

- K-Fold:
  - Divide the code into $k$ equal size sets
  - Train the model on $k-1$ sets and test on the remaining set
- Repeated Random Sampling
  - n number of random samples (20% - 50%)
  - k number of trials
  - Walk over k trails
  - Randomly select n elements for testSet
  - Build model on the rest (trainingSet)
  - Average test results

### Example: Temperature By Year

- Get means for each year and plot them.
- Randomly divide data in half n times.
  - Train on one half of the data.
  - Test on the other half.
  - Record r-squared on test data.
- Report mean r-squared for each dimensionality.

```python
# Initial Class
class tempDatum(object):
    def __init__(self, s):
        info = s.split(',')
        self.high = float(info[1])
        self.year = int(info[2][0:4])
    def getHigh(self):
        return self.high
    def getYear(self):
        return self.year

# Open File    
def getTempData():
    inFile = open('temperatures.csv')
    data = []
    for l in inFile:
        data.append(tempDatum(l))
    return data

# Get Means    
def getYearlyMeans(data):
    years = {}
    for d in data:
        try:
            years[d.getYear()].append(d.getHigh())
        except:
            years[d.getYear()] = [d.getHigh()]
    for y in years:
        years[y] = sum(years[y])/len(years[y])
    return years

# Get and Plot Data
data = getTempData()
years = getYearlyMeans(data)
xVals, yVals = [], []
for e in years:
    xVals.append(e)
    yVals.append(years[e])
pylab.plot(xVals, yVals)
pylab.xlabel('Year')
pylab.ylabel('Mean Daily High (C)')
pylab.title('Select U.S. Cities')

# Initialize Cross Validation
numSubsets = 10
dimensions = (1, 2, 3, 4)
rSquares = {}
for d in dimensions:
    rSquares[d] = []
    
# Split Data
def splitData(xVals, yVals):
    toTrain = random.sample(range(len(xVals)),
                            len(xVals)//2)
    trainX, trainY, testX, testY = [],[],[],[]
    for i in range(len(xVals)):
        if i in toTrain:
            trainX.append(xVals[i])
            trainY.append(yVals[i])
        else:
            testX.append(xVals[i])
            testY.append(yVals[i])
    return trainX, trainY, testX, testY
  
# Train, Test, and Report
for f in range(numSubsets):
    trainX, trainY, testX, testY = splitData(xVals, yVals)
    for d in dimensions:
        model = pylab.polyfit(trainX, trainY, d)
        estYVals = pylab.polyval(model, trainX)
        estYVals = pylab.polyval(model, testX)
        rSquares[d].append(rSquared(testY, estYVals))
print('Mean R-squares for test data')
for d in dimensions:
    mean = round(sum(rSquares[d])/len(rSquares[d]), 4)
    sd = round(numpy.std(rSquares[d]), 4)
    print('For dimensionality', d, 'mean =', mean,
          'Std =', sd)
```

Line seems to be the winner:

- Highest average r-squared.
- Smallest deviation across trials.
- Simplest model.

## Wrapping Up Curve Fitting

- Is a model to predict the value associated with independent values we haven't seen.
- R-squared is used to evaluated model, but higher is not always better because of the risk of over fitting.
- Choose complexity of the model based on theory, cross validation and simplicity.

