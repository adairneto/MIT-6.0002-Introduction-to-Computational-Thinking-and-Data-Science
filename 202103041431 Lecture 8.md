# Lecture 8: Sampling and Standard Error

Tags: #algorithms #python #modeling #simulation #sampling

## Inferential Statistics

Using Monte Carlo to generate random samples and, with them, computing confidence intervals.

What about real samples?

## Probability Sampling

- Each member of the population has a nonzero probability of being included in a sample.
- Simple random sampling: each member has an equal chance of being chosen.
- Not always appropriate. E.g. finding which fraction of MIT students are nerds. But MIT majors are not equally distributed.
- **Stratified sampling:** partition population into subgroups. Take a simple random sample from each subgroup. This is how political polls are made.
  - When it is important that subgroups be represented proportionally to their size in the population.
  - Reduces the needed size of sample bc. the variability of subgroup is less than of entire population.
  - Requires care to do it properly.

### Temperature in US Cities

`numpy.std` returns the standard deviation.

`random.sample(population, sampleSize)` returns a list containing `sampleSize` randomly chosen distinct elements from `population`.

Can or can't be done with replacement.

`pylab.axvline(x=popMean, color ='r')` draws a red vertical line at `popMean` on the `x-axis`.

`pylab.axhline`

Trying 1000 times: the graph looks more like a normal distribution (bc CLT).

### Error Bars

- Graphical representation of the variability of the data.
- Way to visualize uncertainty.
- When confidence intervals don't overlap, we can conclude that means are statistically significantly different at 95% level.

```python
pylab.errorbar(xVals, sizeMeans,
                   yerr = 1.96*pylab.array(sizeSDs), fmt = 'o',
                   label = '95% Confidence Interval')
```

### Supposing that we use only one sample

Thanks to the CLT third property, "The variance of the sample means will be close to the variance of the population divided by the sample size", we compute the **standard deviation of the mean:**
$$
SE = \frac{\sigma}{\sqrt{n}}
$$

```python
def sem(popSD, sampleSize):
  return popSD/sampleSize**0.5
```

Obs: $\sigma$ is the standard deviation of the population.

```python
sampleSizes = (25, 50, 100, 200, 300, 400, 500, 600)
numTrials = 50
population = getHighs()
popSD = numpy.std(population)
sems = []
sampleSDs = []
for size in sampleSizes:
    sems.append(sem(popSD, size))
    means = []
    for t in range(numTrials):
        sample = random.sample(population, size)
        means.append(sum(sample)/len(sample))
    sampleSDs.append(numpy.std(means))
pylab.plot(sampleSizes, sampleSDs,
          label = 'Std of ' + str(numTrials) + ' means')
pylab.plot(sampleSizes, sems, 'r--', label = 'SEM')
pylab.xlabel('Sample Size')
pylab.ylabel('Std and SEM')
pylab.title('SD for ' + str(numTrials) + ' Means and SEM')
pylab.legend()
```

Standard deviation is the variation in the samples.

Standard error we look at one sample.

How to find the standard deviation of the population? Using the sample SD.

Once sample reaches a reasonable size, sample SD is a pretty good approximation to population SD.

```python
def plotDistributions():
    uniform, normal, exp = [], [], []
    for i in range(100000):
        uniform.append(random.random())
        normal.append(random.gauss(0, 1))
        exp.append(random.expovariate(0.5))
    makeHist(uniform, 'Uniform', 'Value', 'Frequency')
    pylab.figure()
    makeHist(normal, 'Gaussian', 'Value', 'Frequency')
    pylab.figure()
    makeHist(exp, 'Exponential', 'Value', 'Frequency')

plotDistributions()
```

Does Distribution matter?

- Skew: a measure of the asymmetry of a probability distribution.
- If the distribution is very asymmetric, you'll need more samples.

Does Population Size matter?

- No because there will be no difference between SDs.

## Estimate Mean from a Single Sample

1. Choose sample size based on estimate of skew in population.
2. Choose a random sample from the population.
3. Compute the mean and the standard deviation of that sample.
4. Use the standard deviation of that sample to estimate the standard error.
5. Use the estimate standard error to generate confidence intervals around the sample mean.

Works great if we choose independent random samples. 

```python
numBad = 0
for t in range(numTrials):
    posStartingPts = range(0, len(temps) - sampleSize)
    start = random.choice(posStartingPts)
    sample = temps[start:start+sampleSize]
    sampleMean = sum(sample)/sampleSize
    se = numpy.std(sample)/sampleSize**0.5
    if abs(popMean - sampleMean) > 1.96*se:
        numBad += 1
print('Fraction outside 95% confidence interval =',
      numBad/numTrials)
```

Expect return: 5%

If your answer is too good, then your answer is wrong. Good results must be aligned to their confidence intervals.